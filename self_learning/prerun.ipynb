{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a00e4b7-5339-4541-9b1a-a358c2cf57fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning up the tables if present\n",
    "dbutils.fs.rm('dbfs:/user/hive/warehouse/', True)\n",
    "tbl = spark.sql(\"SHOW TABLES\").collect()\n",
    "for i in tbl:\n",
    "    spark.sql(f\"DROP TABLE {i.tableName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6454d6c0-dbe0-43b0-a72e-5c63fd2d9596",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>3</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Creating and inserting the table and data\n",
    "-- Create Customers Table\n",
    "CREATE TABLE IF NOT EXISTS Customers (\n",
    "    CustomerID INT,\n",
    "    FirstName VARCHAR(50),\n",
    "    LastName VARCHAR(50),\n",
    "    Email VARCHAR(100)\n",
    ");\n",
    "\n",
    "-- Create Products Table\n",
    "CREATE TABLE IF NOT EXISTS Products (\n",
    "    ProductID INT,\n",
    "    ProductName VARCHAR(100),\n",
    "    Price DECIMAL(10, 2)\n",
    ");\n",
    "\n",
    "-- Create Orders Table\n",
    "CREATE TABLE IF NOT EXISTS Orders (\n",
    "    OrderID INT,\n",
    "    CustomerID INT,\n",
    "    ProductID INT,\n",
    "    Quantity INT,\n",
    "    OrderDate DATE\n",
    ");\n",
    "\n",
    "INSERT INTO Customers (CustomerID, FirstName, LastName, Email)\n",
    "VALUES\n",
    "(1, 'John', 'Doe', 'john.doe@example.com'),\n",
    "(2, 'Jane', 'Smith', 'jane.smith@example.com');\n",
    "\n",
    "-- Insert sample data into Products\n",
    "INSERT INTO Products (ProductID, ProductName, Price)\n",
    "VALUES\n",
    "(1, 'Laptop', 999.99),\n",
    "(2, 'Smartphone', 499.99);\n",
    "\n",
    "-- Insert sample data into Orders\n",
    "INSERT INTO Orders (OrderID, CustomerID, ProductID, Quantity, OrderDate)\n",
    "VALUES\n",
    "(1, 1, 1, 1, '2024-08-01'),\n",
    "(2, 1, 2, 2, '2024-08-02'),\n",
    "(3, 2, 1, 1, '2024-08-03');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "846115aa-0a2b-4050-8711-656cbea3b45e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active tables:-\ncustomers:\n+----------+------------+-------+\n|  col_name|   data_type|comment|\n+----------+------------+-------+\n|CustomerID|         int|   null|\n| FirstName| varchar(50)|   null|\n|  LastName| varchar(50)|   null|\n|     Email|varchar(100)|   null|\n+----------+------------+-------+\n\norders:\n+----------+---------+-------+\n|  col_name|data_type|comment|\n+----------+---------+-------+\n|   OrderID|      int|   null|\n|CustomerID|      int|   null|\n| ProductID|      int|   null|\n|  Quantity|      int|   null|\n| OrderDate|     date|   null|\n+----------+---------+-------+\n\nproducts:\n+-----------+-------------+-------+\n|   col_name|    data_type|comment|\n+-----------+-------------+-------+\n|  ProductID|          int|   null|\n|ProductName| varchar(100)|   null|\n|      Price|decimal(10,2)|   null|\n+-----------+-------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "tbl = spark.sql(\"SHOW TABLES\").collect()\n",
    "print(\"Active tables:-\")\n",
    "for i in tbl:\n",
    "    print(i.tableName+\":\")\n",
    "    spark.sql(f\"DESCRIBE {i.tableName}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e36474-07d9-438c-8752-995a4ea7a44b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Dataframes created:-\ncust_df:\nroot\n |-- CustomerID: integer (nullable = true)\n |-- FirstName: string (nullable = true)\n |-- LastName: string (nullable = true)\n |-- Email: string (nullable = true)\n\nNone\norde_df:\nroot\n |-- OrderID: integer (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- OrderDate: date (nullable = true)\n\nNone\nprod_df:\nroot\n |-- ProductID: integer (nullable = true)\n |-- ProductName: string (nullable = true)\n |-- Price: decimal(10,2) (nullable = true)\n\nNone\n"
     ]
    }
   ],
   "source": [
    "# Creating spark dataframes\n",
    "df_and_commands = {}\n",
    "for i in tbl:\n",
    "    df_name = f\"{i.tableName[:4]}_df\"\n",
    "    df_and_commands[df_name] = spark.read.option('inferSchema', 'true').table(f'{i.tableName}')\n",
    "locals().update(df_and_commands)\n",
    "print(\"Spark Dataframes created:-\")\n",
    "for df_name, df in df_and_commands.items():\n",
    "    print(df_name+\":\")\n",
    "    print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73b792dc-60da-46da-a4e0-f13a8b87a18e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/pandas/utils.py:124: UserWarning: The conversion of DecimalType columns is inefficient and may take a long time. Column names: [Price] If those columns are not necessary, you may consider dropping them or converting to primitive types before the conversion.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Creating Pandas Dataframe\n",
    "pddf_and_commands = {}\n",
    "for df_name, df in df_and_commands.items():\n",
    "    pddf_and_commands[df_name+\"_pd\"] = df.toPandas().infer_objects()\n",
    "locals().update(pddf_and_commands)\n",
    "print(\"Pandas Dataframe created:-\")\n",
    "for df_name, df in pddf_and_commands.items():\n",
    "    print(df_name+\":\")\n",
    "    print(df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2438641724085892,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "prerun",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
